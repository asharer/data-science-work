---
title: "COVID-19"
author: "Angela Sharer"
date: 2020-07-31
output:
  github_document:
    toc: true
---

*Purpose*: We can't *possibly* do a class on data science and *not* look at covid-19. Come on.

In this challenge, you'll learn how to navigate the U.S. Census Bureau website, programmatically download data from the internet, and perform a county-level population-weighted analysis of current covid-19 trends. Get excited!


```{r setup}
library(tidyverse)

```

*Background*: [COVID-19](https://en.wikipedia.org/wiki/Coronavirus_disease_2019) is the disease caused by the virus SARS-CoV-2. In 2020 it became a global pandemic, leading to huge loss of life and tremendous disruption to society. The New York Times published up-to-date data on the progression of the pandemic across the United States---we will study these data in this challenge.

# The Big Picture
<!-- -------------------------------------------------- -->

We're about to go through *a lot* of weird steps, so let's first fix the big picture firmly in mind:

We want to study COVID-19 in terms of data: both case counts (number of infections) and deaths. We're going to do a county-level analysis in order to get a high-resolution view of the pandemic. Since US counties can vary widely in terms of their population, we'll need population estimates in order to compute infection rates (think back to the `Titanic` challenge).

That's the high-level view; now let's dig into the details.

# Get the Data
<!-- -------------------------------------------------- -->

1. County-level population estimates (Census Bureau)
2. County-level COVID-19 counts (New York Times)

## Navigating the Census Bureau
<!-- ------------------------- -->

**Steps**: Our objective is to find the 2018 American Community Survey[1] (ACS) Total Population estimates, disaggregated by counties. To check your results, this is Table `B01003`.

1. Go to [data.census.gov](data.census.gov).
2. Scroll down and click `View Tables`.
3. Apply filters to find the ACS Total Population estimates, disaggregated by counties. I used the filters:
  - `Topics > Populations and People > Counts, Estimates, and Projections > Population Total`
  - `Geography > County > All counties in United States`
5. Click the `Download` button to download the data; make sure to select the 2018 5-year estimates.
6. Unzip and move the data to your `challenges/data` folder.
  - Note that the data will have the crazy-long filename `ACSDT5Y2018.B01003_data_with_overlays_2020-06-30T102151.csv`. That's because metadata is stored in the filename, such as the year of the estimate (`Y2018`) and my access date (`2020-06-30`).

__q1__ Load Table `B01003` into the following tibble. Make sure the column names are `id, Geographic Area Name, Estimate!!Total, Margin of Error!!Total`.

*Hint*: You will need to use the `skip` keyword when loading these data!

```{r q1-task}
## TASK: Load the census bureau data with the following tibble name.
df_pop <- read_csv("./data/ACSDT5Y2018.B01003_data_with_overlays_2020-07-28T114213.csv", skip = 1)

```

*Note*: You can find information on 1-year, 3-year, and 5-year estimates [here](https://www.census.gov/programs-surveys/acs/guidance/estimates.html). The punchline is that 5-year estimates are more reliable but less current.

## Automated Download of NYT Data
<!-- ------------------------- -->

ACS 5-year estimates don't change all that often, but the COVID-19 data are changing rapidly. To that end, it would be nice to be able to *programmatically* download the most recent data for analysis; that way we can update our analysis whenever we want simply by re-running our notebook. This next problem will have you set up such a pipeline.

The New York Times is publishing up-to-date data on COVID-19 on [GitHub](https://github.com/nytimes/covid-19-data).

__q2__ Visit the NYT [GitHub](https://github.com/nytimes/covid-19-data) repo and find the URL for the **raw** US County-level data. Assign that URL as a string to the variable below.

```{r q2-task}
## TASK: Find the URL for the NYT covid-19 county-level data
url_counties <- "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
```

Once you have the url, the following code will download a local copy of the data, then load the data into R.

```{r download}
## NOTE: No need to change this; just execute
## Set the filename of the data to download
filename_nyt <- "./data/nyt_counties.csv"

## Download the data locally
curl::curl_download(
        url_counties,
        destfile = filename_nyt
      )

## Loads the downloaded csv
df_covid <- read_csv(filename_nyt)
```

You can now re-run the chunk above (or the entire notebook) to pull the most recent version of the data. Thus you can periodically re-run this notebook to check in on the pandemic as it evolves.

*Note*: You should feel free to copy-paste the code above for your own future projects!

# Join the Data
<!-- -------------------------------------------------- -->



To get a sense of our task, let's take a glimpse at our two data sources.

```{r glimpse}
## NOTE: No need to change this; just execute
df_pop %>% glimpse
df_covid %>% glimpse
```

To join these datasets, we'll need to use [FIPS county codes](https://en.wikipedia.org/wiki/FIPS_county_code).[2] The last `5` digits of the `id` column in `df_pop` is the FIPS county code, while the NYT data `df_covid` already contains the `fips`.

__q3__ Process the `id` column of `df_pop` to create a `fips` column.

```{r q3-task}
## TASK: Create a `fips` column by extracting the county code
df_q3 <- 
  df_pop %>%
  separate(col = id, into = c("id_short", "fips"), sep = -5)
#df_q3
```

Use the following test to check your answer.

```{r q3-tests}
## NOTE: No need to change this
## Check known county
assertthat::assert_that(
              (df_q3 %>%
              filter(str_detect(`Geographic Area Name`, "Autauga County")) %>%
              pull(fips)) == "01001"
            )
print("Very good!")
```



__q4__ Join `df_covid` with `df_q3` by the `fips` column. Use the proper type of join to preserve all rows in `df_covid`.

```{r q4-task}
## TASK: Join df_covid and df_q3 by fips.
df_q4 <- 
  df_covid %>%
  left_join(df_q3, by = "fips")
#df_q4
```

For convenience, I down-select some columns and produce more convenient column
names.

```{r rename}
## NOTE: No need to change; run this to produce a more convenient tibble
df_data <-
  df_q4 %>%
  select(
    date,
    county,
    state,
    fips,
    cases,
    deaths,
    population = `Estimate!!Total`
  )
```

# Analyze
<!-- -------------------------------------------------- -->

Now that we've done the hard work of loading and wrangling the data, we can finally start our analysis. Our first step will be to produce county population-normalized cases and death counts. Then we will explore the data.

## Normalize
<!-- ------------------------- -->

__q5__ Use the `population` estimates in `df_data` to normalize `cases` and `deaths` to produce per 100,000 counts.[3] Store these values in the columns `cases_perk` and `deaths_perk`.

```{r q5-task}
## TASK: Normalize cases and deaths
df_normalized <-
  df_data %>%
  mutate(
    cases_perk = 100000 * cases / population,
    deaths_perk = 100000 * deaths / population
    )
```

You may use the following test to check your work.

```{r q5-tests}
## NOTE: No need to change this
## Check known county data
assertthat::assert_that(
              abs(df_normalized %>%
               filter(
                 str_detect(county, "Snohomish"),
                 date == "2020-01-21"
               ) %>%
              pull(cases_perk) - 0.127) < 1e-3
            )
assertthat::assert_that(
              abs(df_normalized %>%
               filter(
                 str_detect(county, "Snohomish"),
                 date == "2020-01-21"
               ) %>%
              pull(deaths_perk) - 0) < 1e-3
            )

print("Excellent!")
```

## Guided EDA
<!-- ------------------------- -->

Before turning you loose, let's complete a couple guided EDA tasks.

__q6__ Compute the mean and standard deviation for `cases_perk` and `deaths_perk`.

```{r q6-task}
## TASK: Compute mean and sd for cases_perk and deaths_perk
df_normalized %>%
  summarize(
    mean_cases_per100k = mean(cases_perk, na.rm = TRUE), 
    sd_cases_per100k = sd(cases_perk, na.rm = TRUE),
    mean_deaths_per100k = mean(deaths_perk, na.rm = TRUE),
    sd_deaths_per100k = sd(deaths_perk, na.rm = TRUE)
    )
```

**Note**: Without `na.rm = TRUE`, all of these calculations return as `NA`, and so I know some data must be missing.


__q7__ Find the top 10 counties in terms of `cases_perk`, and the top 10 in terms of `deaths_perk`. Report the population of each county along with the per-100,000 counts. Compare the counts against the mean values you found in q6. Note any observations. Does New York City show up in the top? Why or why not?

```{r q7-task}
## TASK: Find the top 10 max cases_perk counties; report populations as well
top10_cases_perk_counties <-
  df_normalized %>%
  arrange(desc(cases_perk)) %>%
  head(10)
top10_cases_perk_counties

## TASK: Find the top 10 deaths_perk counties; report populations as well
top10_deaths_perk_counties <-
  df_normalized %>%
  arrange(desc(deaths_perk)) %>%
  head(10)
top10_deaths_perk_counties

df_newyorkcity <-
  df_normalized %>%
  filter(county == "New York City") %>%
  arrange(desc(deaths)) %>%
  head(10)
df_newyorkcity

```

**Observations**:

- Currently (7/28/2020), Trousdale TN has the most cases per 100,000 residents, and it has a population of 9,573. 
- Similarly, Hancock GA has the most deaths per 100,000 residents, and it has a population of 8,535.
- New York City does not show up in the top 10; it did not manage to get a population value because it lacks a fips value, as it actually occupies multiple counties.


## Self-directed EDA
<!-- ------------------------- -->

__q8__ Drive your own ship: You've just put together a very rich dataset; you now get to explore! Pick your own direction and generate at least one punchline figure to document an interesting finding. I give a couple tips & ideas below.



### Comparing to New York City

To compare to New York City, I need to first add in its population data. 

```{r Fixing NYC}
## First, I'm finding the NYC population
df_nyc_pop <-
  df_q3 %>% ## This is my dataset of population by county
  filter(
    fips == 36061 | ## New York (Manhattan); this line is equivalent to 
                    ## `Geographic Area Name` == "New York County, New York"
    fips == 36047 | ## Kings
    fips == 36081 | ## Queens
    fips == 36005 | ## Bronx
    fips == 36085   ## Richmond
  ) %>%
  summarize(population = sum(`Estimate!!Total`)) %>%
  mutate(county = "New York City") 

## Next, I'm separating the COVID dataset into NYC-only...
df_covid_nyc <- 
  df_covid %>%
  filter(county == "New York City")
## ... And everything except NYC
df_covid_exceptnyc <-
  df_covid %>%
  filter(county != "New York City")

## Now, our everything-except-NYC data needs population info...
df_data_without_nyc <-
  df_covid_exceptnyc %>%
  left_join(df_q3, by = "fips") %>%
  select(
    date,
    county,
    state,
    fips,
    cases,
    deaths,
    population = `Estimate!!Total`
  )
## ... And so does our NYC data
df_data_with_nyc <-
  df_covid_nyc %>%
  left_join(df_nyc_pop, by = "county")

## Now we are ready to add NYC back in!
df_data_nyc_fixed <-
  df_data_without_nyc %>%
  bind_rows(df_data_with_nyc)

## Now, let's normalize again, and add a few other variables I've been wanting.
df_normalized_full <-
  df_data_nyc_fixed %>%
  mutate(
    cases_perk = 100000 * cases / population,
    deaths_perk = 100000 * deaths / population
    ) %>%
  unite(col = "location", county, state, sep = ", ", remove = FALSE) %>%
  group_by(location) %>%
  mutate(
    max_cases_perk = max(cases_perk), 
    max_deaths_perk = max(deaths_perk)
  ) %>%
  ungroup()
```

My new dataset is `df_normalized_full` ("full" is likely an overstatement, but at least NYC is fixed).

Next, I'd like to see how NYC actually compares to the two counties I discovered earlier with the maximum cases per 100,000 and deaths per 100,000. 

```{r comparing max cases and deaths per 100k of NYC vs July 30 top counties}

df_normalized_full %>%
  filter(
    county == "Hancock" & state == "Georgia" |
    county == "Trousdale" & state == "Tennessee" |
    county == "New York City" & state == "New York"
  ) %>%
  group_by(county) %>%
  summarize(max_cases_perk = max(cases_perk), max_deaths_perk = max(deaths_perk))
```

**Observations**: 

- New York City no longer has the most cases *or* deaths per 100,000 persons.


Let's see which counties exceed New York City. I'll start with the cases per 100,000 people.

```{r worse than NYC cases perk}
df_normalized_full_nyc <-
  df_normalized_full %>%
  filter(county == "New York City" & state == "New York")

nyc_max_cases_perk <-
  df_normalized_full_nyc %>%
  summarize(max_cases_perk = max(cases_perk))

df_worse_than_nyc_cases_perk_obs <-
  df_normalized_full %>%
  filter(cases_perk >= as.double(nyc_max_cases_perk))

df_worse_than_nyc_cases_perk_counties <-  
  df_normalized_full %>%
  semi_join(df_worse_than_nyc_cases_perk_obs, by = c("county", "state"))

df_worse_than_nyc_cases_perk_counties %>%
  ggplot(aes(date, cases_perk)) +
  geom_line(aes(group = location)) +
  geom_line(data = (df_normalized_full_nyc), color = "blue") +
  labs(
    title = "Counties with higher cases per 100,000 persons than NYC",
    x = "Date",
    y = "Cases per 100,000 persons"
  )
```


**Observations**:

- There are more counties here than I would have guessed. Originally I colored the lines by county but the result was not comprehensible...
- I will explore other ways to visualize some of this data. 

```{r taking another run at counties with casesperk worse than nyc}
## TO DO!
```


Next, I'll examine which counties have experienced more deaths per 100,000 than New York City.

```{r worse than NYC deaths perk}
nyc_max_deaths_perk <-
  df_normalized_full_nyc %>%
  summarize(max_deaths_perk = max(deaths_perk))

df_worse_than_nyc_deaths_perk_obs <-
  df_normalized_full %>%
  filter(deaths_perk >= as.double(nyc_max_deaths_perk))

df_worse_than_nyc_deaths_perk_counties <-  
  df_normalized_full %>%
  semi_join(df_worse_than_nyc_deaths_perk_obs, by = c("county", "state"))

df_worse_than_nyc_deaths_perk_counties %>%
  ggplot(aes(date, deaths_perk)) +
  geom_line(aes(color = fct_reorder(location, desc(max_deaths_perk)))) +
  scale_color_discrete(name = "Location") +
  labs(
    title = "Counties with more deaths per 100,000 persons than NYC",
    x = "Date",
    y = "Deaths per 100,000 persons"
  )
```


**Observations**:

- Georgia does not seem to be handling COVID-19 very well. As of 7/31/2020, 4 of 7 counties with more deaths per 100,000 people than New York City are located in Georgia; these are the 4 counties with the most deaths per 100,000 in the country.
- New Mexico, Mississippi, and Virginia each have one county (as of 7/31/2020) with more deaths per 100,000 than New York City, as well. 



### Investigating counties where my family members live

First, I'm making a new dataframe that I can manipulate, which includes the counties where I live, and some of my immediately family members live.

```{r selecting counties where Angela and family live}
df_angela_counties <-
  df_normalized_full %>%
  filter (
    county == "King" & state == "Washington" | 
    county == "Wake" & state == "North Carolina" |
    county == "Durham" & state == "North Carolina" |
    county == "St. Tammany" & state == "Louisiana" #|
#    county == "Franklin" & state == "Alabama" |
#    county == "Jefferson" & state == "Alabama"
  ) 
```

Now I'd like to compare the cases per 100,000 people in these counties.

``` {r cases_perk in the Angela counties}
df_angela_counties %>%
  ggplot(aes(date, cases_perk)) +
  geom_line(aes(color = fct_reorder2(location, date, cases_perk))) +
  scale_color_discrete(name = "County") +
  theme_minimal() +
  labs(
    title = "Cases per 100,000 persons in several US counties",
    x = "Date",
    y = "Cases per 100,000 persons"
  )
```


**Observations**:

- Cases of COVID-19 in King County, Washington (where I live) arose earlier than those in St. Tammany Parish, Louisiana (where my husband's parents live; note that Louisiana uses "Parish" instead of "County") and either of the North Carolina counties (Wake County, where my parents, brother, and his family live, and Durham County, where my sister lives).
- However, cases per 100,000 persons in St. Tammany Parish surpassed King County at the beginning of April (about 5 weeks after Mardi Gras), Durham County surpassed King County in mid-May, and Wake County surpassed King County at the end of June (about 4-5 weeks after Memorial Day).
- *For some context, and without formally looking up any demographics (I should do this), Durham county has a much larger population of black people than Wake County does, even though they are adjacent, and I would guess that both have a larger population of black people than King County does. I'm less sure about St. Tammany Parish; I have spent substantially less time there than any of these other counties.*




``` {r deaths_perk in the Angela counties}
df_angela_counties %>%
  ggplot(aes(date, deaths_perk)) +
  geom_line(aes(color = fct_reorder2(location, date, deaths_perk))) +
  scale_color_discrete(name = "County") +
  theme_minimal() +
  labs(
    title = "Deaths per 100,000 persons in several US counties",
    x = "Date",
    y = "Deaths per 100,000 persons"
  )
```


**Observations**:

- The differences in the trends here from the previous plot are fascinating! 
- King County is doing much worse than the North Carolina counties with respect to deaths per 100,000 persons, even though our case rate is lower (and has been for months, in Durham's case, and about a month, in Wake's case). 
- St. Tammany, though, is doing *much* worse than all other counties here. St. Tammany Parish is just outside New Orleans, and I believe their hospital system became overwhelmed following Mardi Gras (February 25). Deaths on a 6-week delay (a figure I have heard in the news) would explain the spike in deaths per 100,000 persons in early April. 


### Investigating counties where Team Zeta members live

```{r team zeta counties}
## TO DO: Extract team zeta's counties

df_zeta_counties <-
  df_normalized_full %>%
  filter (
    county == "King" & state == "Washington" |          ## Angela
    county == "Multnomah" & state == "Oregon" |         ## Ingrid
    county == "San Mateo" & state == "California" |     ## James
    county == "San Francisco" & state == "California" #| ## Jen
#    county == "Norfolk" & state == "Massachusetts"      ## Olin
  ) 

```


Now, I'd like to visualize the cases per 100,000 persons in the counties of interest to Team Zeta.

```{r team zeta counties casesperk}
df_zeta_counties %>%
  ggplot(aes(date, cases_perk)) +
  geom_line(aes(color = fct_reorder2(location, date, cases_perk))) +
  scale_color_discrete(name = "County") +
  theme_minimal() +
  labs(
    title = "Cases per 100,000 persons in several US counties",
    x = "Date",
    y = "Cases per 100,000 persons"
  )

```


Now, I'd like to visualize the deaths per 100,000 persons in the counties of interest to Team Zeta.

```{r team zeta counties deathsperk}
df_zeta_counties %>%
  ggplot(aes(date, deaths_perk)) +
  geom_line(aes(color = fct_reorder2(location, date, deaths_perk))) +
  scale_color_discrete(name = "County") +
  theme_minimal() +
  labs(
    title = "Cases per 100,000 persons in several US counties",
    x = "Date",
    y = "Deaths per 100,000 persons"
  )

```










# Notes
<!-- -------------------------------------------------- -->

[1] The census used to have many, many questions, but the ACS was created in 2010 to remove some questions and shorten the census. You can learn more in [this wonderful visual history](https://pudding.cool/2020/03/census-history/) of the census.

[2] FIPS stands for [Federal Information Processing Standards](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standards); these are computer standards issued by NIST for things such as government data.

[3] Demographers often report statistics not in percentages (per 100 people), but rather in per 100,000 persons. This is [not always the case](https://stats.stackexchange.com/questions/12810/why-do-demographers-give-rates-per-100-000-people) though!

# Appendix

<!-- include-rubric -->
## Grading Rubric
<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

### Individual
<!-- ------------------------- -->

| Category | Unsatisfactory | Satisfactory |
|----------|----------------|--------------|
| Effort | Some task __q__'s left unattempted | All task __q__'s attempted |
| Observed | Did not document observations | Documented observations based on analysis |
| Supported | Some observations not supported by analysis | All observations supported by analysis (table, graph, etc.) |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

### Team
<!-- ------------------------- -->

| Category | Unsatisfactory | Satisfactory |
|----------|----------------|--------------|
| Documented | No team contributions to Wiki | Team contributed to Wiki |
| Referenced | No team references in Wiki | At least one reference in Wiki to member report(s) |
| Relevant | References unrelated to assertion, or difficult to find related analysis based on reference text | Reference text clearly points to relevant analysis |

### Due Date
<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due on the day of the class discussion of that exercise. See the [Syllabus](https://docs.google.com/document/d/1jJTh2DH8nVJd2eyMMoyNGroReo0BKcJrz1eONi3rPSc/edit?usp=sharing) for more information.

## Suggestions and tips from Zach

### Ideas
<!-- ------------------------- -->

- Look for outliers.
- Try web searching for news stories in some of the outlier counties.
- Investigate relationships between county population and counts.
- Fix the *geographic exceptions* noted below to study New York City.
- Your own idea!

### Aside: Some visualization tricks
<!-- ------------------------- -->

These data get a little busy, so it's helpful to know a few `ggplot` tricks to help with the visualization. Here's an example focused on Massachusetts.

```{r ma-example}
## NOTE: No need to change this; just an example
df_normalized %>%
  filter(state == "Massachusetts") %>%

  ggplot(
    aes(date, cases_perk, color = fct_reorder2(county, date, cases_perk))
  ) +
  geom_line() +
  scale_y_log10(labels = scales::label_number_si()) +
  scale_color_discrete(name = "County") +
  theme_minimal() +
  labs(
    x = "Date",
    y = "Cases (per 100,000 persons)"
  )
```

*Tricks*:

- I use `fct_reorder2` to *re-order* the color labels such that the color in the legend on the right is ordered the same as the vertical order of rightmost points on the curves. This makes it easier to reference the legend.
- I manually set the `name` of the color scale in order to avoid reporting the `fct_reorder2` call.
- I use `scales::label_number_si` to make the vertical labels more readable.
- I use `theme_minimal()` to clean up the theme a bit.
- I use `labs()` to give manual labels.

### Geographic exceptions
<!-- ------------------------- -->

The NYT repo documents some [geographic exceptions](https://github.com/nytimes/covid-19-data#geographic-exceptions); the data for New York, Kings, Queens, Bronx and Richmond counties are consolidated under "New York City" *without* a fips code. Thus the normalized counts in `df_normalized` are `NA`. To fix this, you would need to merge the population data from the New York City counties, and manually normalize the data.
"All cases for the five boroughs of New York City (New York, Kings, Queens, Bronx and Richmond counties) are assigned to a single area called New York City."

### Code snippet from Zach, modified by Angela 
```{r fix-nyc}
df_nyc <-
  df_normalized %>%
  filter(county == "New York City") %>%
  left_join(
    .,
    df_pop %>%
    filter(
      `Geographic Area Name` %in%
      c(
        "New York County, New York",
        "Kings County, New York",
        "Queens County, New York",
        "Bronx County, New York",
        "Richmond County, New York"
      )
    ) %>%
    summarize(pop_nyc = sum(`Estimate!!Total`)),
    by = character()
  ) %>%
  mutate(
    cases_per100k = cases / pop_nyc * 100000,
    deaths_per100k = deaths / pop_nyc * 100000
  ) %>%
  select(
    date,
    county,
    state,
    cases,
    cases_per100k,
    deaths,
    deaths_per100k,
    population = pop_nyc
  )
df_nyc

df_pop %>%
    filter(
      `Geographic Area Name` %in%
      c(
        "New York County, New York",
        "Kings County, New York",
        "Queens County, New York",
        "Bronx County, New York",
        "Richmond County, New York"
      ))
```